# CH13 无监督学习概论

[TOC]

## 前言



### 章节目录

1. 无监督学习基本原理
1. 基本问题
1. 机器学习三要素
1. 无监督学习方法

### 导读

- 在这部分强调了**样本(实例)**，由特征向量组成。
- 无监督学习的基本问题是聚类，降维，概率估计，对应的输出是类别，转换，概率。
- 无监督学习的模型是$z=g_{\theta}(x)$，条件概率分布$P_{\theta}(z|x)$**或条件概率分布$P_{\theta}(x|z)$**
- 训练数据可以用$M\times N$矩阵表示，注意这里矩阵的每一行对应特征，每一列对应一个样本，回想在之前监督学习部分，也是用$N$表示样本的个数。但是这里面其实稍微有一点点尴尬，在监督学习部分，特征的维数用$n$表示，样本数量用$N$表示，在无监督学习部分，特征的维数用$m$表示，样本的数量用$n$表示。
- 无监督学习可以用于数据分析或者监督学习的前处理
- `无监督学习通常需要大量的数据，因为对数据隐藏的规律的发现需要足够的观测`。反过来看，当我们拥有大量数据的时候，可以考虑通过无监督学习的方式来发现数据中隐藏的规律。有的时候我们需要从问题的角度出发来寻找解决方案，而有的时候，我们需要从自身的角度出发，来看能做些什么。不同的岗位看问题的角度不同，但是岗位的差异并不应该限制你思考问题的维度。
- 

## 无监督学习基本原理

符号说明

训练数据集$X$
$$
X=\left[
\begin{matrix}
 x_{11} & \cdots & x_{1N}       \\
 \vdots &        & \vdots 		\\
 x_{M1} & \cdots & x_{MN}       \\
\end{matrix}
\right]
$$

## 基本问题

这个就是任务吧？

### 聚类

### 降维

### 概率模型估计

## 机器学习三要素

### 模型

模型部分条件概率分布$P_\theta(x|z)$这个不是太理解

## 无监督学习方法

### 聚类

CH14，主要是数据硬聚类

### 降维

CH15，CH16，主成分分析，以及奇异值分解。

这部分先写了第16章介绍PCA，然后说的第15章。因为PCA是无监督学习方法，SVD是基础学习方法。后面话题分析部分也是这样的顺序。

### 话题分析

LSA，PLSA，LDA是无监督学习方法，MCMC是基础的学习方法。

### 图分析



## 参考

